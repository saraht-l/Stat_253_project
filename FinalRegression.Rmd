---
title: "Regression"
author: "Claire McHenry, Hilary Kaufman, Sarah Tannert-Lerner, Phebe Chen"
date: "2/15/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)
```

#Load in packages 
```{r, message=FALSE, warning=FALSE}
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(tidymodels) 
tidymodels_prefer()
```


#Load in the datasets
```{r}
#Testing data
NHL.test <- read.csv("test.csv")

#Training data
NHL.train <- read.csv("train.csv")
```

#Select 14 variables to use in the regression model
```{r}
#Clean the data so that there are 14 variables we are looking at 
NHL.regression <- NHL.train %>%
  select(Salary, Ht, Wt, Hand, DftRd, G, A1, DftYr, dzFOL, Cntry, GP,Position,SA)

#MGL, OpFOW not found in this dataset 
#MGL = Games lost due to injury 
#OpFOW = Opening faceoffs won
```

#Data cleaning 
```{r}
#Transform the data so that it's as.numeric for Country 
#ideally make the birth year one whole variable instead of a bunch of yes or no (born variables)
NHL.regression2 <- NHL.regression %>%  
  transform(Cntry,Country=as.numeric(factor(Cntry))) %>% 
  select(Salary, Ht, Wt, Hand, DftRd, G, A1, DftYr, dzFOL, Country, GP, Position, SA)

```

#Creation of CV folds 
```{r}
set.seed(123)
# 6 fold cross validation
NHL.cv6 <- vfold_cv(NHL.regression2, v=6)
```

#Model spec
```{r}
# model specification for OLS
ols.spec <-
    linear_reg() %>% 
    set_engine(engine = 'lm') %>% 
    set_mode('regression')

# model recipe 
lm.recipe <- recipe(Salary ~ ., data = NHL.regression2) %>%
    step_nzv(all_predictors()) %>% # removes variables with the same value
    step_corr(all_numeric_predictors()) %>%
    step_normalize(all_numeric_predictors()) %>% # important standardization step for LASSO
    step_dummy(all_nominal_predictors()) # creates indicator variables for categorical variables

# model workflow
lm.workflow <- workflow() %>%
    add_recipe(lm.recipe) %>%
    add_model(ols.spec)

# fit the model

full_model <- fit(lm.workflow, data = NHL.regression2) 
full_model %>% tidy()

```

#Calculate and collect CV metrics
```{r}
mod1.cv <- fit_resamples(lm.workflow,
  resamples = NHL.cv6, 
  metrics = metric_set(mae,rsq,rmse)
) %>%

collect_metrics(summarize=TRUE)

mod1.cv

model2.cv<-fit_resamples(lm.workflow, #model refits to different cross validation folds
    resamples=NHL.cv6,metrics = metric_set(mae,rsq,rmse))
model2.cv %>% collect_metrics(summarize=TRUE) #shows rsq, mse, rmse values.
```

#LASSO
```{r}
# Model specifications LASSO
lasso.spec <- 
  linear_reg() %>%
  set_args(mixture = 1, penalty = tune()) %>% ## mixture = 1 indicates Lasso
  set_engine(engine = 'glmnet') %>% #note we are using a different engine
  set_mode('regression') 

# rec is same as OLS

# Workflow (Recipe + Model)
lasso_wf_tune <- workflow() %>% 
  add_recipe(lm.recipe) %>% # recipe defined above
  add_model(lasso.spec) 

# Tune Model (trying a variety of values of Lambda penalty)
penalty_grid <- grid_regular(
  penalty(range = c(0, 8)), #log10 transformed
  levels = 30)


tune_output <- tune_grid( # new function for tuning parameters
  lasso_wf_tune, # workflow
  resamples = NHL.cv6, # cv folds
  metrics = metric_set(rmse, mae),
  grid = penalty_grid # penalty grid defined above
)

# Select best model & fit
best_penalty <- tune_output %>% 
  select_by_one_std_err(metric = 'mae', desc(penalty))

ls_mod <-  best_penalty  %>% 
  finalize_workflow(lasso_wf_tune,.) %>%
  fit(data = NHL.regression2) 
    
# Note which variable is the "least" important    
ls_mod %>% tidy()

Credit_final_wk <- finalize_workflow(lasso_wf_tune, best_penalty) # incorporates penalty value to workflow
 
Credit_final_fit <- fit(Credit_final_wk, data = NHL.regression2)

tidy(Credit_final_fit)

```

#Fit and tune models 
```{r}
tune_output %>% collect_metrics() %>% filter(penalty == (best_penalty %>% pull(penalty)))#metrics for first lasso model 
LASSOCV.cv<-fit_resamples(Credit_final_wk, #model refits to different cross validation folds
    resamples=NHL.cv6)
LASSOCV.cv %>% collect_metrics(summarize=TRUE) #shows rsq, and rmse values.
```

#Visualize redisuals 
```{r}
#Evaluate whether some quantitative predictors might be better modeled with nonlinear relationships

LASSO_mod_output <- NHL.regression2%>%
  bind_cols(predict(Credit_final_fit,new_data=NHL.regression2 ))%>%
  mutate(resid=Salary-.pred)


head(LASSO_mod_output)

ggplot(LASSO_mod_output, aes(x = .pred, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()

ggplot(LASSO_mod_output, aes(x = Ht, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()

ggplot(LASSO_mod_output, aes(x = Wt, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()
 
 ggplot(LASSO_mod_output, aes(x = Hand, y = resid)) +
    geom_boxplot() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()
 
 ggplot(LASSO_mod_output, aes(x = DftRd, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()
 
 ggplot(LASSO_mod_output, aes(x = G, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()
 
 ggplot(LASSO_mod_output, aes(x = A1, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()
 
ggplot(LASSO_mod_output, aes(x = DftYr, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()
 
ggplot(LASSO_mod_output, aes(x = dzFOL, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()
 
ggplot(LASSO_mod_output, aes(x = Country, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()

 ggplot(LASSO_mod_output, aes(x = GP, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()
 
 ggplot(LASSO_mod_output, aes(x = Position, y = resid)) +
    geom_boxplot() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()
 
  ggplot(LASSO_mod_output, aes(x = SA, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()
 

```

Which variables are most important predictors of your quantitative outcome? Justify your answer. Do the methods you've applied reach consensus on which variables are most important? What insights are expected? Surprising? NOTE: if some (but not all) of the indicator terms for a categorical predictor are selected in the final models, the whole predictor should be treated as selected. 


```{r}

glmnet_output <- Credit_final_fit %>% extract_fit_parsnip() %>% pluck('fit') # way to get the original glmnet output

lambdas <- glmnet_output$lambda
coefs_lambdas <- 
  coefficients(glmnet_output, s = lambdas )  %>% 
  as.matrix() %>%  
  t() %>% 
  as.data.frame() %>% 
  mutate(lambda = lambdas ) %>% 
  select(lambda, everything(), -`(Intercept)`) %>% 
  pivot_longer(cols = -lambda, 
               names_to = "term", 
               values_to = "coef") %>%
  mutate(var = map_chr(stringr::str_split(term,"_"),~.[1]))

coefs_lambdas %>%
  ggplot(aes(x = lambda, y = coef, group = term, color = var)) +
  geom_line() +
  geom_vline(xintercept = best_penalty %>% pull(penalty), linetype = 'dashed') + 
  theme_classic() + 
  theme(legend.position = "bottom", legend.text=element_text(size=8))
```


Best overall model based on investigations so far? Predictive accuracy? Interpretability? A combination of both?
```{r}
tune_output %>% collect_metrics() %>% filter(penalty == (best_penalty %>% pull(penalty)))#metrics for first lasso model 
LASSOCV.cv<-fit_resamples(Credit_final_wk, #model refits to different cross validation folds
    resamples=NHL.cv6,metrics = metric_set(mae,rsq,rmse))
LASSOCV.cv %>% collect_metrics(summarize=TRUE) 
mod1.cv <- fit_resamples(lm.workflow,
  resamples = NHL.cv6, 
  metrics = metric_set(mae,rsq,rmse)
) %>%

collect_metrics(summarize=TRUE)

mod1.cv

model2.cv<-fit_resamples(lm.workflow, #model refits to different cross validation folds
    resamples=NHL.cv6,metrics = metric_set(mae,rsq,rmse))
model2.cv %>% collect_metrics(summarize=TRUE) #shows rsq, mse, rmse values.
```

Summarize investigations
Decide on an overall best model based on your investigations so far. To do this, make clear your analysis goals. Predictive accuracy? Interpretability? A combination of both?
> We are unclear what the best model is based on our investigations thus far. We are aware that a lot of our variables are not linear as shown in our residual plots. We also know that some of our variables willl likely need to be transformed and we will possbily have to include an interaction term in our regression models. 
Our goals include understanding which of these 14 variables predicts the NHL salary of all players. Right now, there is terrible predictive accuracy. 


Are there any harms that may come from your analyses and/or how the data were collected? What cautions do you want to keep in mind when communicating your work? 

> By making these assessments and pushing out our findings we could be harming outlier players. For example, if our models end up showing that athletes of specific height and specific weight are more likely to succeed, incoming athletes into the NHL may start to desire those weights which could harm them psychologically. However, despite being a weight that may get less pay, there is a possibility that they are an outlier player who could get paid more. 

> Additionally, this data is from the 2016 to 2017 season. As the economy changes, inflation occurs, and the interest in the NHL fluctuates, this will influence the salary of players. We want to keep in mind that when we communicate this data, we make it clear the time period this data reflects and make it known that it may not be completely applicable to previous or future NHL season. 


## Homework 2

#Updated for using natural splines
```{r}
# Use natural splines for some of the quantitative predictors to account for non-linearity (GAMs)
# Use OLS engine
# Update recipe to include step_ns() for each quantitative predictor you want to allow to be non-linear
# Determine number of knots (deg_free) and fit a smoothing spline and use edf to inform your choice
```

```{r}
ggplot(NHL.regression2, aes(x=Ht, y=Salary)) +
    geom_point() +
    geom_smooth(color = "blue", se = FALSE) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    theme_classic()

ggplot(NHL.regression2, aes(x=Wt, y=Salary)) +
    geom_point() +
    geom_smooth(color = "blue", se = FALSE) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    theme_classic()

ggplot(NHL.regression2, aes(x=Hand, y=Salary)) +
    geom_boxplot() +
    geom_smooth(color = "blue", se = FALSE) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    theme_classic()

ggplot(NHL.regression2, aes(x=DftRd, y=Salary)) +
    geom_point() +
    geom_smooth(color = "blue", se = FALSE) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    theme_classic()

ggplot(NHL.regression2, aes(x=G, y=Salary)) +
    geom_point() +
    geom_smooth(color = "blue", se = FALSE) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    theme_classic()

ggplot(NHL.regression2, aes(x=A1, y=Salary)) +
    geom_point() +
    geom_smooth(color = "blue", se = FALSE) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    theme_classic()

ggplot(NHL.regression2, aes(x=DftYr, y=Salary)) +
    geom_point() +
    geom_smooth(color = "blue", se = FALSE) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    theme_classic()

ggplot(NHL.regression2, aes(x=dzFOL, y=Salary)) +
    geom_point() +
    geom_smooth(color = "blue", se = FALSE) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    theme_classic()
 
 ggplot(NHL.regression2, aes(x=GP, y=Salary)) +
    geom_point() +
    geom_smooth(color = "blue", se = FALSE) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    theme_classic()
 
 ggplot(NHL.regression2, aes(x=Position, y=Salary)) +
    geom_boxplot() +
    geom_smooth(color = "blue", se = FALSE) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    
    theme_classic()
 
 ggplot(NHL.regression2, aes(x=SA, y=Salary)) +
    geom_point() +
    geom_smooth(color = "blue", se = FALSE) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    theme_classic()
```
```{r}
set.seed(123)
# Model Spec
lm_spec <-
  linear_reg() %>%
  set_engine(engine = 'lm') %>%
  set_mode('regression')

NHL <- drop_na(NHL.regression2)

# Original Recipe
lm_rec <- recipe(Salary ~ Ht + Wt + DftRd + G + A1 + DftYr + dzFOL + GP + SA, data = NHL) %>%
  step_naomit(all_numeric(), skip = TRUE) %>%
#  step_ns(Ht, deg_free = 3) %>%
  step_ns(Wt, deg_free = 3) %>%
  step_ns(DftRd, deg_free = 3) %>%
  step_ns(G, deg_free = 3) %>%
#  step_ns(A1, deg_free = 3) %>%
  step_ns(DftYr, deg_free = 3) %>%
#  step_ns(dzFOL, deg_free = 3) %>%
  # step_ns(Country, deg_free = 3) %>%
  step_ns(GP, deg_free = 3) %>%
  step_ns(SA, deg_free = 3)

splines_wf <- workflow() %>% 
  add_recipe(lm_rec) %>%
  add_model(lm_spec)
NHL.cv6 <- vfold_cv(NHL, v=6)

# CV to Evaluate
cv_output <- fit_resamples(
  splines_wf, # workflow
  resamples = NHL.cv6, # cv folds
  metrics = metric_set(mae)
)

# cv_output[[4]][[1]]$.notes

cv_output %>% 
  collect_metrics()

# Fit with all data
ns_mod <- fit(
  splines_wf, #workflow
  data = NHL
)

```

```{r}

spline_mod_output <- NHL %>%
    bind_cols(predict(ns_mod, new_data = NHL)) %>% #generates a column of predictions 
    # bind_cols(NHL) %>% #takes what you are inputting and binds it to something else
    mutate(resid = Salary - .pred)

head(spline_mod_output)

ggplot(spline_mod_output, aes(x = .pred, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()


# Residuals vs. predictors (x's)
#ggplot(spline_mod_output, aes(x = Ht, y = resid)) +
#    geom_point() +
#    geom_smooth() +
#    geom_hline(yintercept = 0, color = "red") +
#    theme_classic()

ggplot(spline_mod_output, aes(x = Wt, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()

ggplot(spline_mod_output, aes(x = DftRd, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()

ggplot(spline_mod_output, aes(x = G, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()

#ggplot(spline_mod_output, aes(x = A1, y = resid)) +
#    geom_point() +
#    geom_smooth() +
#    geom_hline(yintercept = 0, color = "red") +
#    theme_classic()

ggplot(spline_mod_output, aes(x = DftYr, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()

#ggplot(spline_mod_output, aes(x = dzFOL, y = resid)) +
#    geom_point() +
#    geom_smooth() +
#    geom_hline(yintercept = 0, color = "red") +
#    theme_classic()

ggplot(spline_mod_output, aes(x = GP, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()

ggplot(spline_mod_output, aes(x = SA, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") +
    theme_classic()
```

```{r}
tune_output %>% collect_metrics() %>% filter(penalty == (best_penalty %>% pull(penalty)))

cv_output %>% collect_metrics()
```
```{r}
# make a plot of predicted vs actual for the salary 

spline_mod_output %>%
  ggplot()+
  geom_point(aes(x=Salary, y=.pred))+
  theme_minimal()
```



Compare insights from variable importance analyses here and the corresponding results from Homework 1.
Now after having accounted for nonlinearity, have the most relevant predictors changed?
> Looking at our analysis of our linear model, the most relevant predictors are shots on goal allowed while players were on ice (SA), handedness of players (Hand), round in which the player was drafted (DftRd), playersâ€™ first assists (A1), and number of goals (G). 
Now that we have accounted for non-linearity, the most relevant predictors appear to be 

Do you gain any insights from the GAM output plots (easily obtained from fitting smoothing splines) for each predictor?
> Salary for hockey players is capped at some point, no matter how many seasonal assists and other ways that they contribute to the team. This relationship is inherently nonlinear, so it is helpful to have a GAM to model that relationship. 
The more goals and individual scores and the more games played and shots against opponent, the higher the residulas become and the more variability in the accuracy of the prediction. 

Compare model performance between your GAM models to the model that assume linearity. 
How does test performance of the GAMs compare to other models you explored?
> Our GAM model has a mean test error of 1,087,752 while the model that assumes linearity has a test error of 125,872. The test performace of the GAMs/splines made the model much worse than the model that assumed linearity. It may also be due to the fact that we took out some variables that we believed were linear variables and perhaps those variables contributed a lot to achieving a low test error. 

Decide on an overall best model based on your investigations so far. To do this, make clear your analysis goals. Predictive accuracy? Interpretability? A combination of both?
> We hope to have predictive accuracy because playing in the NHL is a job and those considering this job may want to understand how their performance on the team will play a role on how much they earn each season. Therefore, we believe that the model that assumes linearity is the best model because it has the lowest test error compared to GAMs by a lot. 

Are there any harms that may come from your analyses and/or how the data were collected? What cautions do you want to keep in mind when communicating your work?
> We hope to change the draft round and edit the data set a little bit. SOMETHING ABOUT THE DRAFT YEAR???? FILL THIS PART IN???
